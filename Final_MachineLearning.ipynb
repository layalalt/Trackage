{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f02d5f-f26d-484c-b469-a175dfbac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c80c716-c79a-47ed-86c5-f296c78431a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/vly_xpw52ss__8lr1wl63j2h0000gn/T/ipykernel_7385/4068909177.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Flight_Arrival_Time\"] = pd.to_datetime(df[\"Flight_Arrival_Time\"])\n",
      "/var/folders/1q/vly_xpw52ss__8lr1wl63j2h0000gn/T/ipykernel_7385/4068909177.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Estimated_Arrival_Time\"] = pd.to_datetime(df[\"Estimated_Arrival_Time\"])\n",
      "/var/folders/1q/vly_xpw52ss__8lr1wl63j2h0000gn/T/ipykernel_7385/4068909177.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Actual_Arrival_Time\"] = pd.to_datetime(df[\"Actual_Arrival_Time\"])\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths and their corresponding passenger counts\n",
    "dataset_info = {\n",
    "    \"luggage_dataset1_128.csv\": 128,\n",
    "    \"luggage_dataset2_128.csv\": 128,\n",
    "    \"luggage_dataset1_250.csv\": 250,\n",
    "    \"luggage_dataset2_250.csv\": 250,\n",
    "    \"luggage_dataset1_300.csv\": 300,\n",
    "    \"luggage_dataset2_300.csv\": 300,\n",
    "    \"luggage_dataset1_350.csv\": 350,\n",
    "    \"luggage_dataset2_350.csv\": 350\n",
    "}\n",
    "\n",
    "# Load and combine all datasets with a new column\n",
    "dfs = []\n",
    "for file_name, passenger_count in dataset_info.items():\n",
    "    df_temp = pd.read_csv(f\"/Users/layal/Desktop/{file_name}\")\n",
    "    df_temp[\"Passenger_Count\"] = passenger_count\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df = df[df['Cluster_Size'] != 1]\n",
    "\n",
    "# Keep only rows with required time columns\n",
    "df = df.dropna(subset=[\n",
    "     'Flight_Arrival_Time', 'Estimated_Arrival_Time', 'Actual_Arrival_Time', 'Cluster_Size'\n",
    "])\n",
    "\n",
    "df[\"Flight_Arrival_Time\"] = pd.to_datetime(df[\"Flight_Arrival_Time\"])\n",
    "df[\"Estimated_Arrival_Time\"] = pd.to_datetime(df[\"Estimated_Arrival_Time\"])\n",
    "df[\"Actual_Arrival_Time\"] = pd.to_datetime(df[\"Actual_Arrival_Time\"])\n",
    "\n",
    "\n",
    "# Now compute the error in seconds\n",
    "df[\"Error_Seconds\"] = (df[\"Actual_Arrival_Time\"] - df[\"Estimated_Arrival_Time\"]).dt.total_seconds()\n",
    "df[\"Error_Minutes\"] = df[\"Error_Seconds\"] / 60\n",
    "\n",
    "# Define features and target\n",
    "y = df[\"Error_Seconds\"].values\n",
    "X = df[['Flight_Arrival_Time', 'Estimated_Arrival_Time', 'Actual_Arrival_Time', 'Cluster_Size', 'Passenger_Count']].copy()\n",
    "\n",
    "\n",
    "def encode_circular_hour(series):\n",
    "    radians = (series / 24) * 2 * np.pi\n",
    "    return np.sin(radians), np.cos(radians)\n",
    "\n",
    "# Extract hour from each datetime and encode circularly\n",
    "for col in ['Flight_Arrival_Time', 'Estimated_Arrival_Time', 'Actual_Arrival_Time']:\n",
    "    hour_col = col + '_Hour'\n",
    "    X[hour_col] = X[col].dt.hour\n",
    "    X[hour_col + '_sin'], X[hour_col + '_cos'] = encode_circular_hour(X[hour_col])\n",
    "\n",
    "# Drop original datetime and hour columns (only keep sine and cosine encodings)\n",
    "X = X.drop(columns=['Flight_Arrival_Time', 'Estimated_Arrival_Time', 'Actual_Arrival_Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d5c65-900d-46f1-94e1-4669f9ef0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   0%|          | 0/4 [00:00<?, ?model/s]"
     ]
    }
   ],
   "source": [
    "# Scale input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=500, random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(kernel='rbf', C=75, epsilon=0.1, gamma='auto'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=10)\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'neg_mae': 'neg_mean_absolute_error',\n",
    "    'neg_mse': 'neg_mean_squared_error'\n",
    "}\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_results = {}\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\", unit=\"model\"):\n",
    "    scores = cross_validate(model, X_trainval, y_trainval, cv=kf, scoring=scoring)\n",
    "\n",
    "    r2 = np.mean(scores['test_r2'])\n",
    "    mae = -np.mean(scores['test_neg_mae'])\n",
    "    mse = -np.mean(scores['test_neg_mse'])\n",
    "    \n",
    "    model_results[name] = {'R2': r2, 'MAE': mae, 'MSE': mse}\n",
    "    print(f\"{name}: CV R² = {r2:.4f}, MAE = {mae:.4f}, MSE = {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83ee7b-af85-4af2-9a92-beaaf857633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    model.fit(X_trainval, y_trainval)            # Train on full 80%\n",
    "    y_pred = model.predict(X_test)                # Predict on 20% test set\n",
    "\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.title(f'{name} Predicted vs Actual on Test Set')\n",
    "    plt.xlabel('Actual Error (seconds)')\n",
    "    plt.ylabel('Predicted Error (seconds)')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729b0e7-8edd-4e20-838e-5e2fe8b28ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model on full data\n",
    "best_model_name = max(model_results, key=model_results.get)\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_scaled, y)\n",
    "\n",
    "# Predict error in seconds\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "\n",
    "# Evaluate MAE\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mae_minutes, mae_seconds = divmod(mae, 60)\n",
    "mae_hours, mae_minutes = divmod(mae_minutes, 60)\n",
    "print(f\"\\n Best Model: {best_model_name} with R² = {model_results[best_model_name]:.4f}\")\n",
    "print(f\" Final MAE: {int(mae_hours)} hours, {int(mae_minutes)} minutes, {int(mae_seconds)} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca2ef0-bdc7-4dfd-afcd-cd6457692ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual error (in seconds)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y, y=y_pred, alpha=0.6)\n",
    "plt.plot([min(y), max(y)], [min(y), max(y)], 'r--')\n",
    "plt.xlabel(\"Actual Error (seconds)\")\n",
    "plt.ylabel(\"Predicted Error (seconds)\")\n",
    "plt.title(\"Actual vs Predicted Error\")\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.axvline(0, color='red', linestyle='dashed')\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Prediction Error (seconds)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7f8f1-a507-442a-8aa9-72621efa983d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
